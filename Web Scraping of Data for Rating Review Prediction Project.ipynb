{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574d10ab",
   "metadata": {},
   "source": [
    "# Web Scraping of Data for Rating Review Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a4963",
   "metadata": {},
   "source": [
    "### Data Collection Phase \n",
    "You have to scrape at least 20000 rows of data. You can scrape more data as well, it’s up to you. \n",
    "more the data better the model\n",
    "\n",
    "In this section you need to scrape the reviews of different laptops, Phones, Headphones, smart \n",
    "watches, Professional Cameras, Printers, Monitors, Home theater, Router from different e\u0002commerce websites.\n",
    "\n",
    "Basically, we need these columns\n",
    "1) reviews of the product.\n",
    "2) rating of the product.\n",
    "\n",
    "You can fetch other data as well, if you think data can be useful or can help in the project. It \n",
    "completely depends on your imagination or assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementClickInterceptedException, ElementNotVisibleException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed1b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the template\n",
    "def get_template(search_term,page_no=1):\n",
    "    \"\"\"Generate a URL for search Term with page number\"\"\"\n",
    "    search_term = search_term.replace(' ','+')\n",
    "    template = f'https://www.amazon.in/s?k={search_term}&page={page_no}&qid=1623864210&ref=sr_pg_{page_no}'\n",
    "    \n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f2f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the URL\n",
    "def get_url():#the function that generated URL with the search tearm.\n",
    "    iteams = ['laptops', 'Phones', 'Headphones', 'smart watches', 'Professional Cameras', 'Printers', 'scanners', 'keyboard', 'monitors', 'Home theater', 'router']\n",
    "    URL = []     \n",
    "    for i in iteams:\n",
    "        for j in range(1,15):\n",
    "            URL.append(get_template(i,j))\n",
    "    return URL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8beda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the review URL\n",
    "def get_review_url(): #the function that scraps the URL of the front page of the reviews and rattings with the search tearm.\n",
    "    \n",
    "    hreff = []\n",
    "    driver = webdriver.Chrome(\"D:\\Downloads\\chromedriver_win\\chromedriver.exe\") \n",
    "    driver.maximize_window()\n",
    "\n",
    "    URL = get_url()\n",
    "    for k in URL:\n",
    "        driver.get(k) #Opening with the URL template\n",
    "\n",
    "        for l in driver.find_elements(By.XPATH,\"//a[@class = 'a-link-normal']\"):\n",
    "            hreff.append(l.get_attribute(\"href\"))   \n",
    "    return hreff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c852f533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = get_review_url()\n",
    "len(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9255105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(): #the function that scraps the URL of all the reviews and rattings\n",
    "    \n",
    "    driver = webdriver.Chrome(r\"D:\\Downloads\\chromedriver_win\\chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.maximize_window()\n",
    "    ratings = []\n",
    "    review = []\n",
    "\n",
    "    for i in href:\n",
    "        driver.get(i) #Opening with the URL template\n",
    "        \n",
    "        try: #scraping the URL of the full review pages\n",
    "            link = driver.find_element(By.XPATH,\"//a[@data-hook='see-all-reviews-link-foot']\")\n",
    "            link = link.get_attribute(\"href\")\n",
    "            link= link.split('ref=cm')[0]\n",
    "        except:\n",
    "            pass     \n",
    "        \n",
    "        for i in range(1,5): #Scraping Reviews and Rattings\n",
    "            l1= f'ref=cm_cr_getr_d_paging_btm_next_{i}?ie=UTF8&reviewerType=all_reviews&pageNumber={i}'\n",
    "            l = link+ l1 \n",
    "            \n",
    "            \n",
    "            driver.get(l)\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            results = soup.find_all('div',{'class' : 'a-section celwidget'})\n",
    "        \n",
    "            for item in results:\n",
    "                    try:\n",
    "                        rev = item.find('span', {'data-hook': \"review-body\"})\n",
    "                        atag = item.find(['a'], class_ = \"a-link-normal\")\n",
    "                        if rev.span.text.replace('\\n','').strip() and atag['title'][0]:\n",
    "                            review.append(rev.span.text.replace('\\n','').strip())\n",
    "                            ratings.append(atag['title'][0])\n",
    "                        else:\n",
    "                            break\n",
    "                    except:\n",
    "                        break\n",
    "       \n",
    "    driver.close()\n",
    "    \n",
    "    rating = pd.DataFrame({'Rattings':ratings, \"Review\": review})\n",
    "    \n",
    "    #saving the dataframe in csv\n",
    "    rating.to_csv(\"Rattings1.csv\",index=False) #Creating CSV\n",
    "    \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6f98f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rattings</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Please don't purchase any Lenovo product.4 mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Please don't purchase any Lenovo product.4 mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Please don't purchase any Lenovo product.4 mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>the laptop whole package is awesome. although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pros:Good specs, others have written enough ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42075</th>\n",
       "      <td>5</td>\n",
       "      <td>I have several of thes across the whole house....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42076</th>\n",
       "      <td>2</td>\n",
       "      <td>This Deco x60 has many limitations compared to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42077</th>\n",
       "      <td>4</td>\n",
       "      <td>HiAlways had a problem of getting strong enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42078</th>\n",
       "      <td>4</td>\n",
       "      <td>I was originally using deco E 4 route and was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42079</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi Everyone,After some early research, I order...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42080 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rattings                                             Review\n",
       "0            1  Please don't purchase any Lenovo product.4 mon...\n",
       "1            1  Please don't purchase any Lenovo product.4 mon...\n",
       "2            1  Please don't purchase any Lenovo product.4 mon...\n",
       "3            4  the laptop whole package is awesome. although ...\n",
       "4            4  Pros:Good specs, others have written enough ab...\n",
       "...        ...                                                ...\n",
       "42075        5  I have several of thes across the whole house....\n",
       "42076        2  This Deco x60 has many limitations compared to...\n",
       "42077        4  HiAlways had a problem of getting strong enoug...\n",
       "42078        4  I was originally using deco E 4 route and was ...\n",
       "42079        1  Hi Everyone,After some early research, I order...\n",
       "\n",
       "[42080 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rat = get_review()\n",
    "Rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bae9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rat.to_csv(\"Ratings_scraped.csv\",index=False)# saving Data frame as CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
